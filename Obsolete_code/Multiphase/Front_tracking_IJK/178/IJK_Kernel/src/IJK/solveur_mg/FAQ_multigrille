
J'ai commencé une faq. On la stocke à quel endroit ?

FAQ Multigrille
===============


Procedure pour determiner les operateurs de deraffinement.

Exemple avec le jeu de donnees NEW-395-2:

Dimensions physiques du maillage 0.187528 x 0.029846 x 0.093764
Nombre de mailles: 448 x 200 x 224
Pas du maillage en x=0.0004185892857142857
Pas du maillage en z=0.0004185892857142857
Pas variable en y (devient la direction K dans le solveur)

Le script generate_coarse.sh genere les deraffinements dans la direction K.
Il faut le construire itérativement.

Creer le fichier coord_k_level0 qui contient les coordonnees de tous les sommets du maillage dans la direction k.
Lancer le script et regarer le fichier "level0_data.txt"

On voit que la taille de la première maille est 0.0000211,
la taille de la plus grande maille est 0.000314459, un tout
petit peu plus petit que le pas du mailllage en x et z.
Le rapport entre la plus petite et la plus grande est 15.
Il faut donc essayer de deraffiner le maillage en k jusqu'a
avoir des mailles de taille 0.0004 environ, identique au pas en x et z.

On peut agglomerer efficacement jusqu'à deux mailles en une à chaque
étape (on peut agglomérer plus mais il faut ensuite beaucoup augmenter
le nombre d'iterations "smooth_steps" pour que le solveur converge,
en général ce n'est pas rentable).

Si on agglomère les deux premières mailles du niveau 0, la plus petite maille sera de taille 0.000043

Si on agglomère à nouveau les deux premières du niveau 1, on arrive à la position du 5eme point, soit 0.00009

Si on agglomère à nouveau, on arrive au 9eme point: 0.000194

Si on agglomère encore, on arrive au 17eme point: 0.00046, c'est bon.

Avec cette agglomération, il faut 4 operations de deraffinement dans la direction k avant de
commencer a deraffiner dans les autres directions.

Le rapport de tailles à obtenir est 0.00042/0.0000211 = 20, sur 4 maillages, pour avoir un maillage isotrope
Le rapport entre deux maillages est racine quatrieme de 20 = 2.1147425
Les tailles des plus petites mailles à utiliser a chaque niveau
niveau0: 0.0000211 (donnee)
niveau1: 0.0000211 * 2.1147425 = 0.000044621
niveau2: 0.000044621 * 2.1147425 = 0.000094362
niveau3: 0.000094362 * 2.1147425 = 0.00019955
niveau4: 0.00019955  * 2.1147425 = 0.0004212

Construction du niveau 1:
-------------------------
agglomerer les mailles par deux sans depasser la taille finale a atteindre en k: 0.0004212
Pour cela, on extrait les indices de points impaires du maillage de depart jusqu'au point
ou la maille a la taille 0.0004212/2=0.0002105, soit le point numero 69 situé à y=0.00607761

qu'on peut faire avec cette ligne dans le script:
>  seq 1 2 69 | extract_points level0_data.txt >tmp

ensuite, on complete avec des points regulierement espaces de 0.0004212 jusqu'au milieu du canal à y=0.014923
(point numero 101) soit un intervalle de 0.014923-0.00607761 a remplir par mailles de taille 0.0004212.
Il en faut (0.014923-0.00607761)/0.0004212 = 21

On peut faire ceci dans le script avec cette ligne:
>  linear 69 101 21 level0_data.txt >>tmp

On termine en symetrisant la liste des coordonnees pour creer les coordonnes du niveau 1:
>  symetry tmp >coord_k_livel1.txt

On execute le script, on obtient 111 coordonnees, soit 110 mailles, soit 55 par moitie de canal.
C'est bien le nombre prevu: 68 mailles deraffinees par 2 = 34 + 21 mailles de taille fixe = 55.

Construction du niveau 2:
-------------------------
Pareil: agglomerer les mailles par deux sans depasser la taille finale a atteindre en k: 0.0004212
On preprocesse les coordonnees du niveau 1 pour pouvoir lire les numeros de points et les tailles
de mailles:

> preprocess coord_k_level1.txt level1_data.txt

Dans le fichier level1_data.txt, on voit que la taille 0.0002105 est atteinte au point numero 23 ou 24
On prend un point sur deux jusqu'a 23 (prendre le  nombre impair le plus proche)
> seq 1 2 23 | extract_points level1_data.txt >tmp

Le point 23 est à y=0.00020465, il faut ajouter 10 mailles pour arriver au point 36 ou
commencent les mailles de taille constante qu'on avait créées toute à l'heure:
> linear 23 36 10 level1_data.txt >> tmp

On recopie les coordonnees exactes des points restants jusqu'au milieu du canal
pour ne pas alourdir le deraffinement (s'il y a correspondance 1 pour 1 entre
mailles fines et grossieres, l'interpolation est triviale,
sinon il y a plus de calculs)
> seq 37 56 | extract_points level1_data.txt >>tmp

Pour finir on symetrise:
>  symetry tmp >coord_k_livel2.txt

On obtient 83 points, soit 82 mailles.

Construction du niveau 3:
-------------------------
Idem:
- deraffiner jusqu'au point 7 ou 8 (on prend 7 parce que ca fait 3 mailles grossieres)
- ajouter des mailles de taille 0.0004212 jusqu'au point 13
   (0.00276052 - 0.000819453) / 0.0004212 = 5 mailles
- copier les points restant jusqu'au milieu du canal (point 42)
- symetriser

>preprocess coord_k_level2.txt level2_data.txt
>seq 1 2 7 | extract_points level2_data.txt >tmp
>linear 7 13 5 level2_data.txt >> tmp
>seq 14 42 | extract_points level2_data.txt >>tmp
>symetry tmp >coord_k_level3.txt

Niveau 4:
----------
>preprocess coord_k_level3.txt level3_data.txt

Le debut du niveau 3 fait ceci:
   1                    0                    0
   2          0.000194404          0.000194404
   3          0.000459637          0.000265233
   4          0.000819453          0.000359816
   5           0.00120767          0.000388217
   6           0.00159588           0.00038821

La maille [4-5] a deja la bonne taille (0.000388217).
Le point 4 est à 0.82.
Il suffit de creer deux mailles entre les points 1 et 4 et de copier les autres

>echo 1 | extract_points level3_data.txt >tmp
>linear 1 4 2 level3_data.txt >> tmp
>seq 5 38 | extract_points level3_data.txt >>tmp
>symetry tmp >coord_k_level4.txt

Le niveau 4 possede 72 mailles, on pourra donc le deraffiner en 36, 18 et 9 si on a envie.
Si ce nombre de convient pas pour les deraffinements suivants il faut changer legerement
les tailles des mailles fixes creees a chaque niveau pour ajouter ou enlever quelques points.

MAIS:
On voudrait pouvoir mettre 2 processeurs dans la direction k, il faudrait donc une maille de plus
ou une maille de moins au dernier niveau pour avoir un nombre pair. Donc il faut arriver
soit à 64 mailles soit à 80 mailles pour le niveau 4.
Allez, on simplifie le niveau 4 avec 64 mailles uniformes. 32 mailles, puis symetrie.

>echo 1 | extract_points level3_data.txt >tmp
>linear 1 38 32 level3_data.txt >> tmp
>symetry tmp >coord_k_level4.txt


Parametres du solveur:
----------------------
Quand le multigrille converge bien, le residu est divise par 10 a chaque iteration.
Pour cela il faut qu'a chaque niveau de grille, les iterations "jacobi" parviennent a
lisser l'erreur venant de la grille grossiere.

Si on active "impr" on peut lire les residus a chaque niveau et a chaque iteration.
Les residus de niveau 0 doivent franchement diminuer entre chaque iteration (facteur 5 à 10).
Les residus entre deux niveaux successifs à la remontée (niveau 4, niveau 3, niveau 2, niveau 1...)
doivent etre proches. S'il y a un gros écart (facteur 5 ou plus) entre deux niveaux à la remontée c'est
que le lisseur jacobi n'a pas réussi à lisser la solution grossière:
- soit les coefficients de la matrice sont mal foutus (trop gros saut de masse volumique, dans ce
cas le problème grossier est une mauvaise approximation du problème fin),
- soit le déraffinement est trop violent (agglomération de plus de 2 ou 3 mailles en 1)
- soit le facteur de relaxation (autour de 0.65) n'est pas optimal.
On peut augmenter le nombre d'iterations jacobi mais si au-delà de 30 ça ne marche toujours pas
c'est qu'il y a un problème.

Le parametre de relaxation optimal (0.65 ou pas loin) et le nombre optimal d'iterations
dependent:
- du rapport de deraffinement entre grilles (5 it pour un rapport 2, 15 it pour un rapport 2.5, ...)
- du nombre de dimensions de derafinement (une seule direction, relaxation 0.7 ou plus, 3 direction 0.65)
- du contenu frequentiel du champ (se mefier des premieres iterations d'un calcul, ca peut
 marcher au debut si les champs sont très lisses et ne plus converger ensuite, il est preferable de
 faire un test avec un champ bruité pour vérifier la convergence du solveur)

Quand on deraffine dans une seule direction avec une agglomeration d'un facteur 2 au maximum,
en general, il faut 5 iterations de "smooth_steps" avec un facteur de relaxation "relax_jacobi"
optimal autour de 0.7.
Quand on deraffine de facon isotrope, le "relax_jacobi" optimal est plutot de 0.65.


"ghost_size" determine le nombre de passes simultanees realisees dans l'algorithme jacobi+residu.
On récupère en un seul échange réseau plusieurs couches de mailles et on effectue plusieurs fois
d'affilée jacobi sans faire d'échange espace virtuel et en restant dans le cache. Cela produit un
nombre total d'opérations plus grand sur si on fait une passe à la fois (les zone ghost sont calculées
par les deux processeurs).
Plus ghost_size est grand, plus on économise la bande passante mémoire car on ne lit qu'une fois
les champs d'entree, sortie et les coefficients de la matrice. La bande passante réseau est un peu
optimisée car les messages sont plus gros et moins nombreux.
Après jacobi, on calcule le residu dans la foulee. Donc si on prend
smooth_steps = 2*ghost_size-1, on utilise de facon optimale le ghost_size choisi.
Conclusion: si on a besoin de
2 iterations jacobi, prendre ghost_size=3
3 iterations jacobi, prendre ghost_size=4
4 iterations jacobi, prendre ghost_size=5
5 iterations jacobi, prendre ghost_size=6
7 iterations : ghost_size=4
9 iterations : ghost_size=5
11 iterations: ghost_size=6
...

Plus ghost_size est grand plus il faut de mémoire cache dans la machine pour que ce soit efficace.
La consommation en cache pour chaque coeur de calcul est approximativement de
8*ghost_size*(nx+2*ghost_size)*(ny+2*ghost_size)*4 octets
(pour le solveur "precision mixed" ou "float") où nx et ny sont la taille d'un bloc en i et j
sur un coeur de calcul.
En général le maximum raisonnable est 6 mais ça peut coincer avant.
Si la bande passante mémoire disponible est grande il vaut mieux diminuer ghost_size car
une grosse zone ghost oblige a faire des calculs supplémentaires.

Attention, la taille des plans de mailles ij sur chaque processeur ne doit pas etre trop grande
(bonne taille: 32x32 jusqu'à 64x64), sinon ça ne rentre plus dans le cache. Si elle est trop petite,
la taille de la zone ghost devient énorme par rapport à la zone utile et c'est inefficace.

Le solveur "solver_precision float" est le plus rapide mais il ne parvient souvent à diminuer le
residu que d'un facteur 10^4 sur les calculs un peu gros.
Le solveur "solveur_precision double" peut diviser le residu d'un facteur 10^12 mais est deux fois
plus lent par iteration, au moins (il est vectorisé SIMD). Comme il consomme plus de mémoire, il
se peut que les données ne rentrent plus dans le cache et que le facteur soit plus important encore.
Le solveur "solveur_precision mixed" calcule le résidu en double precision et le fait decroitre par
des iteration de simple precision (nb iterations determine par nb_full_mg_steps, l'optimum
sur le cas testé est 3, après le residu ne diminue plus trop sur ce cas). Puis on recalcule le
residu en double précision et on rappelle le solveur simple précision.
Sur le cas testé, le solveur "mixed" est presque 3 fois plus rapide que le solveur "double" et
marche jusqu'à un seuil de 10^-12 (residu initial de l'ordre allant de 1 à 10^-2).



Parametres du solveur:

                solveur_pression multigrille_adrien {

            coarsen_operators 7 # from coarse grid to fine grid #
                Coarsen_Operator_Uniform { } # 56 x 28 x 8 #
                Coarsen_Operator_Uniform { } # 112 x 56 x 16 #
                Coarsen_Operator_Uniform { } # 224 x 112 x 32 #
                Coarsen_Operator_K { file_z_coord coord_k_level4.txt } # 448 x 224 x 64 #
                Coarsen_Operator_K { file_z_coord coord_k_level3.txt } # 448 x 224 x 74 #
                Coarsen_Operator_K { file_z_coord coord_k_level2.txt } # 448 x 224 x 82 #
                Coarsen_Operator_K { file_z_coord coord_k_level1.txt } # 448 x 224 x 110 #

            ghost_size 6 # optimal size of ghost zone (depends on the computer processor, 6 is ok most of the time) #
            # for each grid, number of pre-smoothing and post-smoothing iterations (jacobi smoother) #
            pre_smooth_steps 7 5   5   5   5   5   5    11
            smooth_steps     7 5   5   5   5   5   5    11
            # for each grid, relaxation coefficient of the jacobi smoother #
            relax_jacobi     7 0.7 0.7 0.7 0.7 0.7 0.65 0.65 # 0.7 for non isotrop, 0.65 for isotrop #
            perio_i 1
            perio_j 1
            # which solveur for the coarse grid, threshold must be below the global threshold #
            solveur_grossier GCP { seuil  1e-11 precond ssor { omega 1.5 } }
            check_residu 1
            # global threshold #
            seuil 1e-9
            # print residue at each iteration, at each level #
            impr
            nb_full_mg_steps 2 3 1  # 3 iterations at level0 of float solver, 1 recursive iteration at level 2, 3, 4, etc #
            solver_precision mixed

            decoupage 3 TOTO TOTO  2 # 2 processeurs en k #
        }




-- 
Benoit MATHIEU
CEA Grenoble DEN/DER/SSTH/LDAL


