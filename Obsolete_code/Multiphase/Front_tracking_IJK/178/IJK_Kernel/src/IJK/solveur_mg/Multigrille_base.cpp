/****************************************************************************
* Copyright (c) 2015 - 2016, CEA
* All rights reserved.
*
* Redistribution and use in source and binary forms, with or without modification, are permitted provided that the following conditions are met:
* 1. Redistributions of source code must retain the above copyright notice, this list of conditions and the following disclaimer.
* 2. Redistributions in binary form must reproduce the above copyright notice, this list of conditions and the following disclaimer in the documentation and/or other materials provided with the distribution.
* 3. Neither the name of the copyright holder nor the names of its contributors may be used to endorse or promote products derived from this software without specific prior written permission.
*
* THIS SOFTWARE IS PROVIDED BY THE COPYRIGHT HOLDERS AND CONTRIBUTORS "AS IS" AND ANY EXPRESS OR IMPLIED WARRANTIES, INCLUDING, BUT NOT LIMITED TO, THE IMPLIED WARRANTIES OF MERCHANTABILITY AND FITNESS FOR A PARTICULAR PURPOSE ARE DISCLAIMED.
* IN NO EVENT SHALL THE COPYRIGHT HOLDER OR CONTRIBUTORS BE LIABLE FOR ANY DIRECT, INDIRECT, INCIDENTAL, SPECIAL, EXEMPLARY, OR CONSEQUENTIAL DAMAGES (INCLUDING, BUT NOT LIMITED TO, PROCUREMENT OF SUBSTITUTE GOODS OR SERVICES; LOSS OF USE, DATA, OR PROFITS;
* OR BUSINESS INTERRUPTION) HOWEVER CAUSED AND ON ANY THEORY OF LIABILITY, WHETHER IN CONTRACT, STRICT LIABILITY, OR TORT (INCLUDING NEGLIGENCE OR OTHERWISE) ARISING IN ANY WAY OUT OF THE USE OF THIS SOFTWARE, EVEN IF ADVISED OF THE POSSIBILITY OF SUCH DAMAGE.
*
*****************************************************************************/
/////////////////////////////////////////////////////////////////////////////
//
// File      : Multigrille_base.cpp
// Directory : $IJK_ROOT/src/IJK/solveur_mg
//
/////////////////////////////////////////////////////////////////////////////
#include <Multigrille_base.h>
//
// WARNING: DO NOT EDIT THIS FILE! Only edit the template file Multigrille_base.cpp.P
//
#include <Param.h>
#include <DoubleTab.h>
#include <Param.h>
#include <Statistiques.h>
#include <Schema_Comm_Vecteurs.h>
#include <communications.h>
#include <Matrice_Morse_Sym.h>
#include <IJK_discretization.h>
#include <Interprete_bloc.h>
//#define DUMP_LATA_ALL_LEVELS
#ifdef DUMP_LATA_ALL_LEVELS
#include <IJK_lata_dump.h>
#include <IJK_Lata_writer.h>
#endif

// #define DUMP_X_B_AND_RESIDUE_IN_FILE
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
#include <SFichier.h>
static int global_count_dump_in_file = 0;
#endif

Implemente_base_sans_constructeur(Multigrille_base, "Multigrille_base", SolveurSys_base);

Sortie& Multigrille_base::printOn(Sortie& os) const
{
  return os;
}

void Multigrille_base::ajouter_param(Param& param)
{
  param.ajouter("relax_jacobi", &relax_jacobi_);
  param.ajouter("pre_smooth_steps", &pre_smooth_steps_);
  param.ajouter("smooth_steps", &smooth_steps_);
  param.ajouter("nb_full_mg_steps", &nb_full_mg_steps_);
  param.ajouter("solveur_grossier", &solveur_grossier_);
  param.ajouter("check_residu", &check_residu_);
  param.ajouter("seuil", &seuil_);
  param.ajouter("iterations_gcp", &max_iter_gcp_);
  param.ajouter("iterations_gmres", &max_iter_gmres_);
  param.ajouter("solv_jacobi", &solv_jacobi_);
  param.ajouter("n_krilov", &n_krilov_);
  param.ajouter_flag("impr", &impr_);
  param.ajouter("solver_precision", &solver_precision_);
  param.dictionnaire("double", precision_double_);
  param.dictionnaire("float", precision_float_);
  param.dictionnaire("mixed", precision_mix_);
  param.ajouter("iterations_mixed_solver", &max_iter_mixed_solver_);
}

Multigrille_base::Multigrille_base() : precision_double_(0), precision_float_(1),
  precision_mix_(2)
{
  check_residu_ = 0;
  seuil_ = 0.;
  max_iter_gcp_ = 0; // default, use multigrid solver, not gcp
  max_iter_gmres_ = 0; // default, use multigrid solver, not gmres
  n_krilov_ = 3;
  impr_ = 0;
  impr_gmres_ = 2;
  solv_jacobi_ = 0;
  solver_precision_ = precision_double_;
  relax_jacobi_.resize_array(1);
  relax_jacobi_[0] = 0.65;
  max_iter_mixed_solver_ = 4;
}

Entree& Multigrille_base::readOn(Entree& is)
{
  Process::exit();
  return is;
}

void triangularise(const DoubleTab& hessenberg, const double norme_b, DoubleTab& resu, ArrOfDouble& r)
{
  const int n = hessenberg.dimension(1);
  assert(hessenberg.dimension(0) == n+1);
  assert(r.size_array() == n + 1);

  r[0] = norme_b;

  // Triangularisation
  int i;
  for(i = 0; i < n; i++)
    {
      double ccos, ssin;
      {
        const double h_ii = hessenberg(i, i);
        const double h_i1i = hessenberg(i + 1, i);
        const double tmp_val = 1. / sqrt(h_ii * h_ii + h_i1i * h_i1i);
        ccos = h_ii * tmp_val;
        ssin = - h_i1i * tmp_val;
      }
      for (int j = i; j < n; j++)
        {
          const double h_ij = hessenberg(i, j);
          const double h_i1j = hessenberg(i + 1, j);
          resu(i, j)     = ccos * h_ij - ssin * h_i1j;
          resu(i + 1, j) = ssin * h_ij + ccos * h_i1j;
        }
      const double ri = r[i];
      r[i] = ccos * ri;
      r[i + 1] = ssin * ri;
    }
}


#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
void dump_x_b_residue_in_file(const IJK_Field_float& x, const IJK_Field_float& b, IJK_Field_float& residu,
                              int grid_level, int step_number, Nom comment)
{

  if (Process::je_suis_maitre())
    {
      const int ni = x.ni();
      const int j_fix = 3;
      const int k_fix = 3;
      Nom n("plot_step");
      char ss[4];
      sprintf(ss, "%03d", step_number);
      n += Nom(ss);
      n += Nom("_level");
      n += Nom(grid_level);
      n += Nom(".txt");
      SFichier f(n/* , ios::out --> default*/);
      f.setf(ios::scientific);
      for (int i = 0; i < ni; i++)
        {
          const float xx = x(i,j_fix, k_fix);
          const float bb = b(i,j_fix, k_fix);
          const float rr = residu(i,j_fix, k_fix);
          f << i << " " << xx << " " << bb << " " << rr << finl;
        }
      Cout << "STEP " << global_count_dump_in_file << " at grid level " << grid_level << " " << comment << finl;
      global_count_dump_in_file++;
    }
}
#endif

// Methode recursive qui resout A*x = b et calcule residu = A*x-b
//  pour le niveau de grille grid_level.
//  Si grid_level = niveau grossier, appel a coarse_solver,
//  sinon iterations sur
//    pre_smoothing, coarsening, appel recursif, interpolation, post_smoothing
// input: b
// output: x, residu
// return value = L2 norm of the residue
double Multigrille_base::multigrille_(IJK_Field_float& x, const IJK_Field_float& b, IJK_Field_float& residu,
                                      int grid_level, int iter_number)
{
  double norme_residu_final = 0.;
  const int needed_kshift = needed_kshift_for_jacobi(grid_level + 1);
#ifdef DUMP_LATA_ALL_LEVELS
  IJK_Field_float copy_residu_for_post(residu);
  copy_residu_for_post.data() = 0.;
  IJK_Field_float copy_x_for_post(x);
  IJK_Field_float copy_xini_for_post(x);
  copy_xini_for_post.data() = x.data();
#endif
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
  dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("avt pre-smooth / recursive call / coarse solver"));
#endif
  // Recurse
  if (grid_level < nb_grid_levels() - 1)
    {
      // Pre-smooting
      {
        const int pss = (grid_level >= pre_smooth_steps_.size_array())
                        ? pre_smooth_steps_[pre_smooth_steps_.size_array()-1]
                        : pre_smooth_steps_[grid_level];
        jacobi_residu(x, &b, grid_level, pss /* jacobi iterations */, &residu);
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
        dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("apres pre-smooth"));
#endif
      }
#ifdef DUMP_LATA_ALL_LEVELS
      copy_x_for_post.data() = x.data();
#endif
      norme_residu_final = norme_ijk(residu);
      if (impr_)
        Cout << "level=" << grid_level << " residu(pre)=" << norme_residu_final << finl;

      IJK_Field_float& coarse_b = get_storage_float(STORAGE_RHS, grid_level + 1);
      IJK_Field_float& coarse_x = get_storage_float(STORAGE_X, grid_level + 1);
      IJK_Field_float& coarse_residu = get_storage_float(STORAGE_RESIDUE, grid_level + 1);

      const int nmax = nb_full_mg_steps_.size_array() - 1;
      int nb_full = 1;
      if (iter_number != 0 || grid_level <= 1)
        {
          if (grid_level > nmax)
            nb_full = nb_full_mg_steps_[nmax];
          else
            nb_full = nb_full_mg_steps_[grid_level];
        }

      for (int fmg_step = 0; fmg_step < nb_full; fmg_step++)
        {
#ifdef DUMP_LATA_ALL_LEVELS
          copy_residu_for_post = residu;
#endif
          // Coarsen residual
          coarse_b.data() = 0.;
          coarsen(residu, coarse_b, grid_level);

          // It seems that the residue has non zero sum due to accumulation of
          // roundoff errors when computing A*x. At the coarse level, we get
          // a wrong rhs...
          prepare_secmem(coarse_b);

          // We need one less layer on b than on x to compute jacobi or residue
          coarse_b.echange_espace_virtuel(b.ghost()-1);
          // Solve for coarse_x
          coarse_x.shift_k_origin(needed_kshift - coarse_x.k_shift());
          coarse_x.data() = 0.;
          //coarse_x.shift_k_origin(coarse_x.k_shift_max() - coarse_x.k_shift());
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
          // inutile : idem avt avt-presmooth pour grid-level+1
          //  dump_x_b_residue_in_file(coarse_x,coarse_b,coarse_residu, grid_level+1, global_count_dump_in_file, Nom("avt recursive-call"));
#endif
          multigrille_(coarse_x, coarse_b, coarse_residu, grid_level+1, fmg_step);
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
          dump_x_b_residue_in_file(coarse_x,coarse_b,coarse_residu, grid_level+1, global_count_dump_in_file, Nom("avt interpol / apres recursive-call/jacobi-residu/ou/coarse-solver "));
#endif

          // Interpolate and substract to x
          // Shift by n layers in k for the next jacobi_residu call
          interpolate_sub_shiftk(coarse_x, x, grid_level);
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
          IJK_Field_float copy_x_to_compute_res(x);
          copy_x_to_compute_res.data() = x.data();
          const int g = x.ghost();
          const int imin = x.linear_index(-g,-g,-g);
          const int imax = x.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1;
          assert(imin == copy_x_to_compute_res.linear_index(-g,-g,-g));
          assert(imax == copy_x_to_compute_res.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1);
          float *ptr = x.data().addr();
          const float *ptr2 = copy_x_to_compute_res.data().addr();
          for (int i = imin; i < imax; i++)
            ptr[i] -= ptr2[i];

          jacobi_residu(copy_x_to_compute_res, &b, grid_level, 0 /* no jacobi iterations, just compute residu */, &residu);
          dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("apres interpol"));
#endif
          // Post smoothing iterations
          {
            const int postss = (grid_level >= smooth_steps_.size_array())
                               ? smooth_steps_[smooth_steps_.size_array()-1]
                               : smooth_steps_[grid_level];
            jacobi_residu(x, &b, grid_level, postss /* jacobi iterations */, &residu);
          }
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
          dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("apres post-smooth"));
#endif
#ifdef DUMP_LATA_ALL_LEVELS
          {
            static ArrOfInt step;
            if (step.size_array() < grid_level + 1)
              step.resize_array(grid_level + 1);

            const Nom lata_name = Nom("Multigrid_level") + Nom(grid_level) + Nom(".lata");
            if (step[grid_level] == 0)
              {
                Nom dom = Nom("DOM")+Nom(grid_level);
                IJK_Grid_Geometry& geom = ref_cast_non_const(IJK_Grid_Geometry,x.get_splitting().get_grid_geometry() );
                geom.nommer(dom); // On nomme la geom pour pouvoir l'ecrire.
                dumplata_header(lata_name, x /* on passe un champ pour ecrire la geometrie */);
              }
            dumplata_newtime(lata_name,step[grid_level]);
            dumplata_scalar(lata_name, "xini", copy_x_for_post, step[grid_level]);
            dumplata_scalar(lata_name, "x1", copy_x_for_post, step[grid_level]);
            dumplata_scalar(lata_name, "xf", x, step[grid_level]);
            dumplata_scalar(lata_name, "b", b, step[grid_level]);
            dumplata_scalar(lata_name, "residu1", copy_residu_for_post, step[grid_level]);
            dumplata_scalar(lata_name, "residue", residu, step[grid_level]);
            step[grid_level]++;
          }
#endif

          norme_residu_final = norme_ijk(residu);
          if (impr_)
            Cout << "level=" << grid_level << " residu=" << norme_residu_final << finl;
          // use threshold criteria only if pure multigrid (not gcp with mg preconditionning)
          if (grid_level == 0 && norme_residu_final < seuil_ && max_iter_gcp_ == 0)
            break;
        }
    }
  else
    {
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
      // inutile : idem avt avt-presmooth pour grid-level
      // dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("avt coarse-solver"));
#endif
      coarse_solver(x, b);
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
      // inutile : idem avt interpol
      // dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("apres coarse-solver"));
#endif
      jacobi_residu(x, &b, grid_level, 0 /* not jacobi */, &residu);
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
      // inutile : idem avt interpol
      // dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("apres jacobi-residu"));
#endif

      norme_residu_final = norme_ijk(residu);
      if (impr_)
        Cout << finl << "level=" << grid_level << " residu=" << norme_residu_final
             << " (coarse solver)" << finl;
#ifdef DUMP_LATA_ALL_LEVELS
      {
        static ArrOfInt step;
        if (step.size_array() < grid_level + 1)
          step.resize_array(grid_level + 1);

        const Nom lata_name = Nom("Multigrid_level") + Nom(grid_level) + Nom(".lata");
        if (step[grid_level] == 0)
          {
            Nom dom = Nom("DOM")+Nom(grid_level);
            x.get_splitting_non_const().get_grid_geometry_non_const().nommer(dom); // On nomme la geom pour pouvoir l'ecrire.
            dumplata_header(lata_name, x /* on passe un champ pour ecrire la geometrie */);
          }
        dumplata_newtime(lata_name,step[grid_level]);
        dumplata_scalar(lata_name, "x", x, step[grid_level]);
        dumplata_scalar(lata_name, "b", b, step[grid_level]);
        dumplata_scalar(lata_name, "residue", residu, step[grid_level]);
        step[grid_level]++;
      }
#endif
    }
  return norme_residu_final;
}

void Multigrille_base::coarse_solver(IJK_Field_float& x, const IJK_Field_float& b)
{
  const Matrice_Grossiere& mat = coarse_matrix_;

  DoubleVect inco;
  DoubleVect secmem;
  const MD_Vector& md = mat.md_vector();
  inco.resize(md.valeur().get_nb_items_tot());
  inco.set_md_vector(md);
  secmem = inco;

  int ni = x.ni();
  int nj = x.nj();
  int nk = x.nk();
  int i, j, k;
  static Stat_Counter_Id counter = statistiques().new_counter(0, "coarse_solver");
  statistiques().begin_count(counter);

  for (k = 0; k < nk; k++)
    for (j = 0; j < nj; j++)
      for (i = 0; i < ni; i++)
        secmem[mat.renum(i,j,k)] = b(i,j,k);

  secmem.echange_espace_virtuel();
  solveur_grossier_.resoudre_systeme(mat.matrice(), secmem, inco);

  for (k = 0; k < nk; k++)
    for (j = 0; j < nj; j++)
      for (i = 0; i < ni; i++)
        x(i,j,k) = inco[mat.renum(i,j,k)];


  statistiques().end_count(counter);
}

double Multigrille_base::multigrille(IJK_Field_float& x, const IJK_Field_float& b, IJK_Field_float& residu)
{
  return multigrille_(x, b, residu, 0, 0);
}

// Can be further optimized for float (extend Schema_Comm_Vecteurs to float)
void Multigrille_base::convert_to_ijk(const DoubleVect& x, IJK_Field_float& ijk_x)
{
  // fetch the vdf_to_ijk translator (assume there is one unique object, with conventional name)
  const char * ijkdis_name = IJK_discretization::get_conventional_name();
  const IJK_discretization& ijkdis = ref_cast(IJK_discretization, Interprete_bloc::objet_global(ijkdis_name));
  ijkdis.get_vdf_to_ijk(IJK_Splitting::ELEM).convert_to_ijk(x, ijk_x);
}

// Can be further optimized for float (extend Schema_Comm_Vecteurs to float)
void Multigrille_base::convert_from_ijk(const IJK_Field_float& ijk_x, DoubleVect& x)
{
  // fetch the vdf_to_ijk translator (assume there is one unique object, with conventional name)
  const char * ijkdis_name = IJK_discretization::get_conventional_name();
  const IJK_discretization& ijkdis = ref_cast(IJK_discretization, Interprete_bloc::objet_global(ijkdis_name));
  ijkdis.get_vdf_to_ijk(IJK_Splitting::ELEM).convert_from_ijk(ijk_x, x);
}

void op_negate(IJK_Field_float& x)
{
  const int g = x.ghost();
  const int imin = x.linear_index(-g,-g,-g);
  const int imax = x.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1;
  float *ptr = x.data().addr();
  for (int i = imin; i < imax; i++)
    ptr[i] = -ptr[i];
}

void op_multiply(IJK_Field_float& x, float a)
{
  const int g = x.ghost();
  const int imin = x.linear_index(-g,-g,-g);
  const int imax = x.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1;
  float *ptr = x.data().addr();
  for (int i = imin; i < imax; i++)
    ptr[i] *= a;
}

void op_sub(IJK_Field_float& x, const IJK_Field_float& y)
{
  const int g = x.ghost();
  const int imin = x.linear_index(-g,-g,-g);
  const int imax = x.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1;
  assert(imin == y.linear_index(-g,-g,-g));
  assert(imax == y.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1);
  float *ptr = x.data().addr();
  const float *ptr2 = y.data().addr();
  for (int i = imin; i < imax; i++)
    ptr[i] -= ptr2[i];
}

void ajoute_alpha_v(IJK_Field_float& x, float alpha, const IJK_Field_float& v)
{
  const int g = x.ghost();
  const int imin = x.linear_index(-g,-g,-g);
  const int imax = x.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1;
  assert(imin == v.linear_index(-g,-g,-g));
  assert(imax == v.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1);
  float *ptr = x.data().addr();
  const float *ptr2 = v.data().addr();
  for (int i = imin; i < imax; i++)
    ptr[i] += alpha * ptr2[i];
}

// Ne semble pas fonctionner (manque juste echange espace virtuel sur second membre ?)
void Multigrille_base::resoudre_avec_gcp(IJK_Field_float& x, IJK_Field_float& b, IJK_Field_float& residu)
{
  IJK_Field_float Z, P, R;
  alloc_field(Z, 0);
  alloc_field(P, 0);
  alloc_field(R, 0);
  x.data() = 0.;
  R.data() = b.data();
  op_negate(R);

  multigrille(P, R, residu);
#if 0
  P.data() = R.data();
#elif 0
  P.data() = 0.;
  jacobi_residu(P, &R, 0 /* grid_level */, 2 /* number of jacobi iterations */,
                0 /* do not compute residue */);
  //operator_negate(P.data());
#endif

  float dold = prod_scal_ijk(R, P);
  op_negate(P);

  for (int iter = 0; iter < max_iter_gcp_; iter++)
    {
      // calcul de AP = A * P
      jacobi_residu(P, 0 /* secmem */, 0 /* grid_level */, 0 /* no jacobi */, &residu);

      float alpha = dold / prod_scal_ijk(P, residu);

      Cout << "alpha=" << alpha << " normeP=" << norme_ijk(P) << " dold=" << dold << finl;

      ajoute_alpha_v(x, alpha, P);

      ajoute_alpha_v(R, alpha, residu);

      float nr = norme_ijk(R);
      Cout << "GCP+MG iteration " << iter << " residu " << nr << finl;
      if (nr < seuil_)
        break;

      if (iter == max_iter_gcp_)
        {
          Cerr << "Non convergence de Multigrille_poreux::resoudre_avec_gcp en " << max_iter_gcp_
               << " iterations" << finl;
          break;
        }

      // preconditionner
      multigrille(Z, R, residu);
#if 0
      Z.data() = R.data();
#elif 0
      Z.data() = 0.;
      jacobi_residu(Z, &R, delta_x, 0 /* grid_level */, 2 /* number of jacobi iterations */,
                    0);
      //operator_negate(Z.data());
#endif

      float prodscal_RZ = prod_scal_ijk(R, Z);
      float beta = prodscal_RZ / dold;
      dold = prodscal_RZ;

      op_multiply(P, beta);
      op_sub(P, Z);
    }
}
#if 0
// Conjugate Gradient using the optimized ijk storage
void Multigrille_base::gcp_ssor(IJK_Field_float& x, IJK_Field_float& b, IJK_Field_float& residu,
                                IJK_Field_float& coeffs_faces, double seuil, double omega)
{
  IJK_Field_float R(b);
  x.data() = 0.;
  IJK_Field_float P(x); // equal zero
  IJK_Field_float Z(x); // alsa equal zero
  op_negate(R);

  multigrille(P, R, residu);
#if 0
  P.data() = R.data();
#elif 0
  P.data() = 0.;
  jacobi_residu(P, &R, 0 /* grid_level */, 2 /* number of jacobi iterations */,
                0 /* do not compute residue */);
  //operator_negate(P.data());
#endif

  float dold = prod_scal_ijk(R, P);
  op_negate(P);

  while (norm_residue > threshold && niter++ < nmax)
    {
      // Exchange 1 layer of ghost elements
      P.echange_espace_virtuel(1);
      // Compute resu = A * P and dot product resu * P
      local_resu_dot_p = ijk_coeff_multiply_and_dot(coeffs_faces, P, resu);
      resu_dot_p = mp_sum(local_resu_dot_p);
      alpha = previous_residue_dot_precond / resu_dot_p;
      ajoute_alpha_v(tmp_solution, alpha, P);
      local_residue_dot_residue = ajoute_alpha_v_sqrnorm(residue, alpha, resu);

      // Preconditionning:
      if (with_ssor)
        {
          residue.echange_espace_virtuel();
          // Apply ssor to residue, store result in resu and compute local part of residue dot resu:
          local_residue_dot_precond = ssor_and_dotproduct(A, residue, resu);

          {
            // sum on all processors:
            residue_dot_precond = local_residue_dot_precond;
            residue_dot_residue = local_residue_dot_residue;
            mpsum_multiple(residue_dot_precond, residue_dot_residue);
          }
          if (residue_dot_precond < 0.)
            {
              Cerr << "Error in ijk gcp_ssor: residue dot resu < 0. (non postitive matrix ?)" << endl;
              exit();
            }

          tmp_p = tmp_p * (residue_dot_resu / previous_residue_dot_resu) - resu;
          dold = residue_dot_resu;
        }
      else
        {
          residue_dot_resu = ;
          exit();
        }
      norm_residue = sqrt(residue_dot_residue);
    }



  // calcul de AP = A * P
  jacobi_residu(P, 0 /* secmem */, 0 /* grid_level */, 0 /* no jacobi */, &residu);

  float alpha = dold / prod_scal_ijk(P, residu);

  Cout << "alpha=" << alpha << " normeP=" << norme_ijk(P) << " dold=" << dold << finl;

  ajoute_alpha_v(x, alpha, P);

  ajoute_alpha_v(R, alpha, residu);

  float nr = norme_ijk(R);
  Cout << "GCP+MG iteration " << iter << " residu " << nr << finl;
  if (nr < seuil_)
    break;

  if (iter == max_iter_gcp_)
    {
      Cerr << "Non convergence de Multigrille_poreux::resoudre_avec_gcp en " << max_iter_gcp_
           << " iterations" << finl;
      break;
    }

  // preconditionner
  multigrille(Z, R, residu);
#if 0
  Z.data() = R.data();
#elif 0
  Z.data() = 0.;
  jacobi_residu(Z, &R, delta_x, 0 /* grid_level */, 2 /* number of jacobi iterations */,
                0);
  //operator_negate(Z.data());
#endif

  float prodscal_RZ = prod_scal_ijk(R, Z);
  float beta = prodscal_RZ / dold;
  dold = prodscal_RZ;

  op_multiply(P, beta);
  op_sub(P, Z);
}
}

#endif

inline double ajouter_alpha_v_multiple_(IJK_Field_float& x, ArrOfDouble& coeff, VECT(IJK_Field_float) & y, int n, int nfirst)
{
  if (n > 4)
    {
      Cerr << "Erreur ajouter_alpha_v_multiple" << finl;
      Process::exit();
    }
  const int ni = x.ni();
  const int nj = x.nj();
  const int nk = x.nk();
  float * x_ptr = x.data().addr();
  float * y_ptr[4];
  float c[4];
  int nn;
  double somme = 0.;
  for (nn = 0; nn < n; nn++)
    {
      y_ptr[nn] = y[nfirst + nn].data().addr();
      c[nn] = coeff[nfirst + nn];
    }
  for (int k = 0; k < nk; k++)
    {
      for (int j = 0; j < nj; j++)
        {
          int index = x.linear_index(0,j,k);
          for (int i = 0; i < ni; i++)
            {
              float val = x_ptr[index+i];
              for (nn = 0; nn < n; nn++)
                val += c[nn] * y_ptr[nn][index+i];
              x_ptr[index+i] = val;
              somme += val * val;
            }
        }
    }
  return somme;
}

// Calcule ceci
//   x += coeff[0] * y[0] + ... + coeff[n-1] * y[n-1]
// Renvoie la somme des x^2 du resultat sur le processeur local
double ajouter_alpha_v_multiple(IJK_Field_float& x, ArrOfDouble& coeff, VECT(IJK_Field_float) & y, int n)
{
  int i = 0;
  double somme = 0.;
  while (i < n)
    {
      int nn = n - i;
      if (nn > 4)
        nn = 4;
      if (nn == 1)
        somme += ajouter_alpha_v_multiple_(x, coeff, y, 1, i);
      else if (nn == 2)
        somme += ajouter_alpha_v_multiple_(x, coeff, y, 2, i);
      else if (nn == 3)
        somme += ajouter_alpha_v_multiple_(x, coeff, y, 3, i);
      else if (nn == 4)
        somme += ajouter_alpha_v_multiple_(x, coeff, y, 4, i);

      i += nn;
    }
  return somme;
}

inline void calcul_produits_scalaires_(VECT(IJK_Field_float) & x, int n, int nfirst, int m, ArrOfDouble& resu)
{
  if (n > 4)
    {
      Cerr << "Erreur " << finl;
      Process::exit();
    }
  const int ni = x[0].ni();
  const int nj = x[0].nj();
  const int nk = x[0].nk();
  float * x_ptr = x[m].data().addr();
  float * y_ptr[4];
  float c[4] = { 0., 0., 0., 0. };
  int nn;
  for (nn = 0; nn < n; nn++)
    {
      y_ptr[nn] = x[nfirst + nn].data().addr();
      c[nn] = 0;
    }
  for (int k = 0; k < nk; k++)
    {
      for (int j = 0; j < nj; j++)
        {
          int index = x[0].linear_index(0,j,k);
          for (int i = 0; i < ni; i++)
            {
              float val = x_ptr[index+i];
              for (nn = 0; nn < n; nn++)
                c[nn] += val * y_ptr[nn][index+i];
            }
        }
    }
  for (nn = 0; nn < n; nn++)
    resu[nfirst + nn] += c[nn];
}

// Calcule ceci, pour i=0..n avec n = resu.size_array()-1
//   resu[i] = x[i] scalaire x[n]
// Renvoie la somme des x^2 du resultat sur le processeur local
void calcul_produits_scalaires(VECT(IJK_Field_float) & x, ArrOfDouble& resu)
{
  int i = 0;
  resu = 0.;
  const int n = resu.size_array() - 1;
  while (i < n)
    {
      int nn = n - i;
      if (nn > 4)
        nn = 4;
      if (nn == 1)
        calcul_produits_scalaires_(x, 1, i, n, resu);
      else if (nn == 2)
        calcul_produits_scalaires_(x, 2, i, n, resu);
      else if (nn == 3)
        calcul_produits_scalaires_(x, 3, i, n, resu);
      else if (nn == 4)
        calcul_produits_scalaires_(x, 4, i, n, resu);
      i += nn;
    }
  mp_sum_for_each_item(resu);
}

// Gmres preconditionne par multigrille.
// si plus de 3 vecteurs de base, semble atteindre la limite de precision numerique...
void Multigrille_base::resoudre_avec_gmres(IJK_Field_float& x, IJK_Field_float& b, IJK_Field_float& residu)
{
  int n_krilov = n_krilov_;
  DoubleTab hessenberg(n_krilov + 1, n_krilov);

  // Espace de Krilov
  VECT(IJK_Field_float) krilov_space;
  // Vecteurs des M^(-1) * krilov_space[i] ou M^-1 est le preconditionneur:
  VECT(IJK_Field_float) m_krilov_space;

  {
    IJK_Field_float titi;
    for (int ii=0; ii < n_krilov+1; ii++)
      krilov_space.add(titi);
    for (int ii=0; ii < n_krilov; ii++)
      m_krilov_space.add(titi);
  }
  krilov_space[0] = b;
  for (int ii=0; ii < n_krilov; ii++)
    {
      //int sz = b.data().size_array();
#if 0
      krilov_space[ii+1].data().resize_array(sz);
      m_krilov_space[ii].data().resize_array(sz);
#endif
      alloc_field(krilov_space[ii+1], 0);
      alloc_field(m_krilov_space[ii], 0, true /* with additional layers for jacobi sweeps */);
    }

  x.data() = 0.;

  for (int iter = 0; ; iter++)
    {

      // Hypothese de depart: krilov_space[0] = -residu
      const double norme_b = norme_ijk(krilov_space[0]);

      if (impr_gmres_)
        Cout << "gmres iteration " << iter << " norme(residu) " << norme_b << finl;
      if (norme_b < seuil_ || norme_b == 0.)
        {
          if (impr_gmres_)
            Cout << "gmres: norme(residu) < seuil=" << seuil_ << " => return" << finl;
          return;
        }
      if (iter >= max_iter_gmres_)
        {
          Cerr << "Error in Multigrille_base::resoudre_avec_gmres: did not converge in " << max_iter_gmres_ << " restarts."
               << "\n Residue= " << norme_b << finl;
          Process::exit();
        }
      krilov_space[0].data() *= (1. / norme_b);

      hessenberg = 0.;

      for (int i = 0; i < n_krilov; i++)
        {
          // Produit matrice vecteur : v1 = A * M^(-1) * v0  (ou M^(-1) est une approx de A^(-1) par multigrille)
          m_krilov_space[i].data() = 0.;
          m_krilov_space[i].shift_k_origin(needed_kshift_for_jacobi(0) - m_krilov_space[i].k_shift());
          krilov_space[i].echange_espace_virtuel(krilov_space[i].ghost());
          // Stockage de M^-1 * v0 dans m_krilov_space[i]
          // et on met le residu dans krilov_space[i+1]
          multigrille(m_krilov_space[i], krilov_space[i], krilov_space[i+1]);

          // remarque Titi23
          // On obtient krilov_space[i+1] = A * m_krilov_space[i] - krilov_space[i]
          // normalement, on devrait faire
          //  krilov_space[i+1] += krilov_space[i]
          // L'orthogonalisation va retirer la composante krilov_space[i],
          // mais va calculer "prod_scal_ijk(krilov_space[i+1], krilov_space[i]) - 1"

          // Orthogonalisation:
          //  v0 = somme pour 0 <= j <= i des (krilov_space[j] * hessenberg(j, i)
          ArrOfDouble produit_scal(i+2);
          ArrOfDouble coeff(i+1);
          calcul_produits_scalaires(krilov_space, produit_scal);
          for (int j = 0; j <= i; j++)
            {
              double h = produit_scal[j];
              coeff[j] = -h;
              //norme2_prevue -= h*h;
              if (j == i)
                {
                  // voir Titi23 ci-dessus:
                  // on n'a pas rajoute krilov_space[i] toute a l'heure a krilov_space[i+1],
                  // le produit scalaire a stocker dans hessenberg vaut donc 1 de plus:
                  h += 1.;
                }
              hessenberg(j, i) = h;
            }
          double norme_v0 = ajouter_alpha_v_multiple(krilov_space[i+1], coeff, krilov_space, i+1);
          norme_v0 = sqrt(mp_sum(norme_v0));
          hessenberg(i + 1, i) = norme_v0;
          krilov_space[i+1].data() *= 1. / norme_v0;
        }

      DoubleTab mat(n_krilov + 1, n_krilov);
      ArrOfDouble r__(n_krilov + 1);
      triangularise(hessenberg, norme_b, mat, r__);

      //...Solution of linear system
      for (int i = n_krilov - 1; i >= 0; i--)
        {
          r__[i] /= mat(i, i);
          for (int j = i-1; j >= 0; j--)
            r__[j] -= mat(j, i) * r__[i];
        }
      ajouter_alpha_v_multiple(x, r__, m_krilov_space, n_krilov);
      if (impr_gmres_)
        {
          Cout << "facteurs r : ";
          for (int i = 0; i < r__.size_array(); i++)
            Cout << r__[i] << " ";
          Cout << finl;
          if (impr_gmres_ > 1)
            {
              Cout << "matrice de hessenberg " << hessenberg << finl;
            }
        }
      // On stocke le residu dans krilov_space[0] pour l'iteration suivante:
      jacobi_residu(x, &b, 0 /* grid_level */, 0 /* no jacobi */, &krilov_space[0]);
      prepare_secmem(krilov_space[0]);
      op_negate(krilov_space[0]);
    }
}

#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
void dump_x_b_residue_in_file(const IJK_Field_double& x, const IJK_Field_double& b, IJK_Field_double& residu,
                              int grid_level, int step_number, Nom comment)
{

  if (Process::je_suis_maitre())
    {
      const int ni = x.ni();
      const int j_fix = 3;
      const int k_fix = 3;
      Nom n("plot_step");
      char ss[4];
      sprintf(ss, "%03d", step_number);
      n += Nom(ss);
      n += Nom("_level");
      n += Nom(grid_level);
      n += Nom(".txt");
      SFichier f(n/* , ios::out --> default*/);
      f.setf(ios::scientific);
      for (int i = 0; i < ni; i++)
        {
          const double xx = x(i,j_fix, k_fix);
          const double bb = b(i,j_fix, k_fix);
          const double rr = residu(i,j_fix, k_fix);
          f << i << " " << xx << " " << bb << " " << rr << finl;
        }
      Cout << "STEP " << global_count_dump_in_file << " at grid level " << grid_level << " " << comment << finl;
      global_count_dump_in_file++;
    }
}
#endif

// Methode recursive qui resout A*x = b et calcule residu = A*x-b
//  pour le niveau de grille grid_level.
//  Si grid_level = niveau grossier, appel a coarse_solver,
//  sinon iterations sur
//    pre_smoothing, coarsening, appel recursif, interpolation, post_smoothing
// input: b
// output: x, residu
// return value = L2 norm of the residue
double Multigrille_base::multigrille_(IJK_Field_double& x, const IJK_Field_double& b, IJK_Field_double& residu,
                                      int grid_level, int iter_number)
{
  double norme_residu_final = 0.;
  const int needed_kshift = needed_kshift_for_jacobi(grid_level + 1);
#ifdef DUMP_LATA_ALL_LEVELS
  IJK_Field_double copy_residu_for_post(residu);
  copy_residu_for_post.data() = 0.;
  IJK_Field_double copy_x_for_post(x);
  IJK_Field_double copy_xini_for_post(x);
  copy_xini_for_post.data() = x.data();
#endif
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
  dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("avt pre-smooth / recursive call / coarse solver"));
#endif
  // Recurse
  if (grid_level < nb_grid_levels() - 1)
    {
      // Pre-smooting
      {
        const int pss = (grid_level >= pre_smooth_steps_.size_array())
                        ? pre_smooth_steps_[pre_smooth_steps_.size_array()-1]
                        : pre_smooth_steps_[grid_level];
        jacobi_residu(x, &b, grid_level, pss /* jacobi iterations */, &residu);
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
        dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("apres pre-smooth"));
#endif
      }
#ifdef DUMP_LATA_ALL_LEVELS
      copy_x_for_post.data() = x.data();
#endif
      norme_residu_final = norme_ijk(residu);
      if (impr_)
        Cout << "level=" << grid_level << " residu(pre)=" << norme_residu_final << finl;

      IJK_Field_double& coarse_b = get_storage_double(STORAGE_RHS, grid_level + 1);
      IJK_Field_double& coarse_x = get_storage_double(STORAGE_X, grid_level + 1);
      IJK_Field_double& coarse_residu = get_storage_double(STORAGE_RESIDUE, grid_level + 1);

      const int nmax = nb_full_mg_steps_.size_array() - 1;
      int nb_full = 1;
      if (iter_number != 0 || grid_level <= 1)
        {
          if (grid_level > nmax)
            nb_full = nb_full_mg_steps_[nmax];
          else
            nb_full = nb_full_mg_steps_[grid_level];
        }

      for (int fmg_step = 0; fmg_step < nb_full; fmg_step++)
        {
#ifdef DUMP_LATA_ALL_LEVELS
          copy_residu_for_post = residu;
#endif
          // Coarsen residual
          coarse_b.data() = 0.;
          coarsen(residu, coarse_b, grid_level);

          // It seems that the residue has non zero sum due to accumulation of
          // roundoff errors when computing A*x. At the coarse level, we get
          // a wrong rhs...
          prepare_secmem(coarse_b);

          // We need one less layer on b than on x to compute jacobi or residue
          coarse_b.echange_espace_virtuel(b.ghost()-1);
          // Solve for coarse_x
          coarse_x.shift_k_origin(needed_kshift - coarse_x.k_shift());
          coarse_x.data() = 0.;
          //coarse_x.shift_k_origin(coarse_x.k_shift_max() - coarse_x.k_shift());
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
          // inutile : idem avt avt-presmooth pour grid-level+1
          //  dump_x_b_residue_in_file(coarse_x,coarse_b,coarse_residu, grid_level+1, global_count_dump_in_file, Nom("avt recursive-call"));
#endif
          multigrille_(coarse_x, coarse_b, coarse_residu, grid_level+1, fmg_step);
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
          dump_x_b_residue_in_file(coarse_x,coarse_b,coarse_residu, grid_level+1, global_count_dump_in_file, Nom("avt interpol / apres recursive-call/jacobi-residu/ou/coarse-solver "));
#endif

          // Interpolate and substract to x
          // Shift by n layers in k for the next jacobi_residu call
          interpolate_sub_shiftk(coarse_x, x, grid_level);
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
          IJK_Field_double copy_x_to_compute_res(x);
          copy_x_to_compute_res.data() = x.data();
          const int g = x.ghost();
          const int imin = x.linear_index(-g,-g,-g);
          const int imax = x.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1;
          assert(imin == copy_x_to_compute_res.linear_index(-g,-g,-g));
          assert(imax == copy_x_to_compute_res.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1);
          double *ptr = x.data().addr();
          const double *ptr2 = copy_x_to_compute_res.data().addr();
          for (int i = imin; i < imax; i++)
            ptr[i] -= ptr2[i];

          jacobi_residu(copy_x_to_compute_res, &b, grid_level, 0 /* no jacobi iterations, just compute residu */, &residu);
          dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("apres interpol"));
#endif
          // Post smoothing iterations
          {
            const int postss = (grid_level >= smooth_steps_.size_array())
                               ? smooth_steps_[smooth_steps_.size_array()-1]
                               : smooth_steps_[grid_level];
            jacobi_residu(x, &b, grid_level, postss /* jacobi iterations */, &residu);
          }
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
          dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("apres post-smooth"));
#endif
#ifdef DUMP_LATA_ALL_LEVELS
          {
            static ArrOfInt step;
            if (step.size_array() < grid_level + 1)
              step.resize_array(grid_level + 1);

            const Nom lata_name = Nom("Multigrid_level") + Nom(grid_level) + Nom(".lata");
            if (step[grid_level] == 0)
              {
                Nom dom = Nom("DOM")+Nom(grid_level);
                IJK_Grid_Geometry& geom = ref_cast_non_const(IJK_Grid_Geometry,x.get_splitting().get_grid_geometry() );
                geom.nommer(dom); // On nomme la geom pour pouvoir l'ecrire.
                dumplata_header(lata_name, x /* on passe un champ pour ecrire la geometrie */);
              }
            dumplata_newtime(lata_name,step[grid_level]);
            dumplata_scalar(lata_name, "xini", copy_x_for_post, step[grid_level]);
            dumplata_scalar(lata_name, "x1", copy_x_for_post, step[grid_level]);
            dumplata_scalar(lata_name, "xf", x, step[grid_level]);
            dumplata_scalar(lata_name, "b", b, step[grid_level]);
            dumplata_scalar(lata_name, "residu1", copy_residu_for_post, step[grid_level]);
            dumplata_scalar(lata_name, "residue", residu, step[grid_level]);
            step[grid_level]++;
          }
#endif

          norme_residu_final = norme_ijk(residu);
          if (impr_)
            Cout << "level=" << grid_level << " residu=" << norme_residu_final << finl;
          // use threshold criteria only if pure multigrid (not gcp with mg preconditionning)
          if (grid_level == 0 && norme_residu_final < seuil_ && max_iter_gcp_ == 0)
            break;
        }
    }
  else
    {
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
      // inutile : idem avt avt-presmooth pour grid-level
      // dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("avt coarse-solver"));
#endif
      coarse_solver(x, b);
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
      // inutile : idem avt interpol
      // dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("apres coarse-solver"));
#endif
      jacobi_residu(x, &b, grid_level, 0 /* not jacobi */, &residu);
#ifdef DUMP_X_B_AND_RESIDUE_IN_FILE
      // inutile : idem avt interpol
      // dump_x_b_residue_in_file(x,b,residu, grid_level, global_count_dump_in_file, Nom("apres jacobi-residu"));
#endif

      norme_residu_final = norme_ijk(residu);
      if (impr_)
        Cout << finl << "level=" << grid_level << " residu=" << norme_residu_final
             << " (coarse solver)" << finl;
#ifdef DUMP_LATA_ALL_LEVELS
      {
        static ArrOfInt step;
        if (step.size_array() < grid_level + 1)
          step.resize_array(grid_level + 1);

        const Nom lata_name = Nom("Multigrid_level") + Nom(grid_level) + Nom(".lata");
        if (step[grid_level] == 0)
          {
            Nom dom = Nom("DOM")+Nom(grid_level);
            x.get_splitting_non_const().get_grid_geometry_non_const().nommer(dom); // On nomme la geom pour pouvoir l'ecrire.
            dumplata_header(lata_name, x /* on passe un champ pour ecrire la geometrie */);
          }
        dumplata_newtime(lata_name,step[grid_level]);
        dumplata_scalar(lata_name, "x", x, step[grid_level]);
        dumplata_scalar(lata_name, "b", b, step[grid_level]);
        dumplata_scalar(lata_name, "residue", residu, step[grid_level]);
        step[grid_level]++;
      }
#endif
    }
  return norme_residu_final;
}

void Multigrille_base::coarse_solver(IJK_Field_double& x, const IJK_Field_double& b)
{
  const Matrice_Grossiere& mat = coarse_matrix_;

  DoubleVect inco;
  DoubleVect secmem;
  const MD_Vector& md = mat.md_vector();
  inco.resize(md.valeur().get_nb_items_tot());
  inco.set_md_vector(md);
  secmem = inco;

  int ni = x.ni();
  int nj = x.nj();
  int nk = x.nk();
  int i, j, k;
  static Stat_Counter_Id counter = statistiques().new_counter(0, "coarse_solver");
  statistiques().begin_count(counter);

  for (k = 0; k < nk; k++)
    for (j = 0; j < nj; j++)
      for (i = 0; i < ni; i++)
        secmem[mat.renum(i,j,k)] = b(i,j,k);

  secmem.echange_espace_virtuel();
  solveur_grossier_.resoudre_systeme(mat.matrice(), secmem, inco);

  for (k = 0; k < nk; k++)
    for (j = 0; j < nj; j++)
      for (i = 0; i < ni; i++)
        x(i,j,k) = inco[mat.renum(i,j,k)];


  statistiques().end_count(counter);
}

double Multigrille_base::multigrille(IJK_Field_double& x, const IJK_Field_double& b, IJK_Field_double& residu)
{
  return multigrille_(x, b, residu, 0, 0);
}

// Can be further optimized for float (extend Schema_Comm_Vecteurs to float)
void Multigrille_base::convert_to_ijk(const DoubleVect& x, IJK_Field_double& ijk_x)
{
  // fetch the vdf_to_ijk translator (assume there is one unique object, with conventional name)
  const char * ijkdis_name = IJK_discretization::get_conventional_name();
  const IJK_discretization& ijkdis = ref_cast(IJK_discretization, Interprete_bloc::objet_global(ijkdis_name));
  ijkdis.get_vdf_to_ijk(IJK_Splitting::ELEM).convert_to_ijk(x, ijk_x);
}

// Can be further optimized for float (extend Schema_Comm_Vecteurs to float)
void Multigrille_base::convert_from_ijk(const IJK_Field_double& ijk_x, DoubleVect& x)
{
  // fetch the vdf_to_ijk translator (assume there is one unique object, with conventional name)
  const char * ijkdis_name = IJK_discretization::get_conventional_name();
  const IJK_discretization& ijkdis = ref_cast(IJK_discretization, Interprete_bloc::objet_global(ijkdis_name));
  ijkdis.get_vdf_to_ijk(IJK_Splitting::ELEM).convert_from_ijk(ijk_x, x);
}

void op_negate(IJK_Field_double& x)
{
  const int g = x.ghost();
  const int imin = x.linear_index(-g,-g,-g);
  const int imax = x.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1;
  double *ptr = x.data().addr();
  for (int i = imin; i < imax; i++)
    ptr[i] = -ptr[i];
}

void op_multiply(IJK_Field_double& x, double a)
{
  const int g = x.ghost();
  const int imin = x.linear_index(-g,-g,-g);
  const int imax = x.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1;
  double *ptr = x.data().addr();
  for (int i = imin; i < imax; i++)
    ptr[i] *= a;
}

void op_sub(IJK_Field_double& x, const IJK_Field_double& y)
{
  const int g = x.ghost();
  const int imin = x.linear_index(-g,-g,-g);
  const int imax = x.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1;
  assert(imin == y.linear_index(-g,-g,-g));
  assert(imax == y.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1);
  double *ptr = x.data().addr();
  const double *ptr2 = y.data().addr();
  for (int i = imin; i < imax; i++)
    ptr[i] -= ptr2[i];
}

void ajoute_alpha_v(IJK_Field_double& x, double alpha, const IJK_Field_double& v)
{
  const int g = x.ghost();
  const int imin = x.linear_index(-g,-g,-g);
  const int imax = x.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1;
  assert(imin == v.linear_index(-g,-g,-g));
  assert(imax == v.linear_index(x.ni()-1+g, x.nj()-1+g, x.nk()-1+g) + 1);
  double *ptr = x.data().addr();
  const double *ptr2 = v.data().addr();
  for (int i = imin; i < imax; i++)
    ptr[i] += alpha * ptr2[i];
}

// Ne semble pas fonctionner (manque juste echange espace virtuel sur second membre ?)
void Multigrille_base::resoudre_avec_gcp(IJK_Field_double& x, IJK_Field_double& b, IJK_Field_double& residu)
{
  IJK_Field_double Z, P, R;
  alloc_field(Z, 0);
  alloc_field(P, 0);
  alloc_field(R, 0);
  x.data() = 0.;
  R.data() = b.data();
  op_negate(R);

  multigrille(P, R, residu);
#if 0
  P.data() = R.data();
#elif 0
  P.data() = 0.;
  jacobi_residu(P, &R, 0 /* grid_level */, 2 /* number of jacobi iterations */,
                0 /* do not compute residue */);
  //operator_negate(P.data());
#endif

  double dold = prod_scal_ijk(R, P);
  op_negate(P);

  for (int iter = 0; iter < max_iter_gcp_; iter++)
    {
      // calcul de AP = A * P
      jacobi_residu(P, 0 /* secmem */, 0 /* grid_level */, 0 /* no jacobi */, &residu);

      double alpha = dold / prod_scal_ijk(P, residu);

      Cout << "alpha=" << alpha << " normeP=" << norme_ijk(P) << " dold=" << dold << finl;

      ajoute_alpha_v(x, alpha, P);

      ajoute_alpha_v(R, alpha, residu);

      double nr = norme_ijk(R);
      Cout << "GCP+MG iteration " << iter << " residu " << nr << finl;
      if (nr < seuil_)
        break;

      if (iter == max_iter_gcp_)
        {
          Cerr << "Non convergence de Multigrille_poreux::resoudre_avec_gcp en " << max_iter_gcp_
               << " iterations" << finl;
          break;
        }

      // preconditionner
      multigrille(Z, R, residu);
#if 0
      Z.data() = R.data();
#elif 0
      Z.data() = 0.;
      jacobi_residu(Z, &R, delta_x, 0 /* grid_level */, 2 /* number of jacobi iterations */,
                    0);
      //operator_negate(Z.data());
#endif

      double prodscal_RZ = prod_scal_ijk(R, Z);
      double beta = prodscal_RZ / dold;
      dold = prodscal_RZ;

      op_multiply(P, beta);
      op_sub(P, Z);
    }
}
#if 0
// Conjugate Gradient using the optimized ijk storage
void Multigrille_base::gcp_ssor(IJK_Field_double& x, IJK_Field_double& b, IJK_Field_double& residu,
                                IJK_Field_double& coeffs_faces, double seuil, double omega)
{
  IJK_Field_double R(b);
  x.data() = 0.;
  IJK_Field_double P(x); // equal zero
  IJK_Field_double Z(x); // alsa equal zero
  op_negate(R);

  multigrille(P, R, residu);
#if 0
  P.data() = R.data();
#elif 0
  P.data() = 0.;
  jacobi_residu(P, &R, 0 /* grid_level */, 2 /* number of jacobi iterations */,
                0 /* do not compute residue */);
  //operator_negate(P.data());
#endif

  double dold = prod_scal_ijk(R, P);
  op_negate(P);

  while (norm_residue > threshold && niter++ < nmax)
    {
      // Exchange 1 layer of ghost elements
      P.echange_espace_virtuel(1);
      // Compute resu = A * P and dot product resu * P
      local_resu_dot_p = ijk_coeff_multiply_and_dot(coeffs_faces, P, resu);
      resu_dot_p = mp_sum(local_resu_dot_p);
      alpha = previous_residue_dot_precond / resu_dot_p;
      ajoute_alpha_v(tmp_solution, alpha, P);
      local_residue_dot_residue = ajoute_alpha_v_sqrnorm(residue, alpha, resu);

      // Preconditionning:
      if (with_ssor)
        {
          residue.echange_espace_virtuel();
          // Apply ssor to residue, store result in resu and compute local part of residue dot resu:
          local_residue_dot_precond = ssor_and_dotproduct(A, residue, resu);

          {
            // sum on all processors:
            residue_dot_precond = local_residue_dot_precond;
            residue_dot_residue = local_residue_dot_residue;
            mpsum_multiple(residue_dot_precond, residue_dot_residue);
          }
          if (residue_dot_precond < 0.)
            {
              Cerr << "Error in ijk gcp_ssor: residue dot resu < 0. (non postitive matrix ?)" << endl;
              exit();
            }

          tmp_p = tmp_p * (residue_dot_resu / previous_residue_dot_resu) - resu;
          dold = residue_dot_resu;
        }
      else
        {
          residue_dot_resu = ;
          exit();
        }
      norm_residue = sqrt(residue_dot_residue);
    }



  // calcul de AP = A * P
  jacobi_residu(P, 0 /* secmem */, 0 /* grid_level */, 0 /* no jacobi */, &residu);

  double alpha = dold / prod_scal_ijk(P, residu);

  Cout << "alpha=" << alpha << " normeP=" << norme_ijk(P) << " dold=" << dold << finl;

  ajoute_alpha_v(x, alpha, P);

  ajoute_alpha_v(R, alpha, residu);

  double nr = norme_ijk(R);
  Cout << "GCP+MG iteration " << iter << " residu " << nr << finl;
  if (nr < seuil_)
    break;

  if (iter == max_iter_gcp_)
    {
      Cerr << "Non convergence de Multigrille_poreux::resoudre_avec_gcp en " << max_iter_gcp_
           << " iterations" << finl;
      break;
    }

  // preconditionner
  multigrille(Z, R, residu);
#if 0
  Z.data() = R.data();
#elif 0
  Z.data() = 0.;
  jacobi_residu(Z, &R, delta_x, 0 /* grid_level */, 2 /* number of jacobi iterations */,
                0);
  //operator_negate(Z.data());
#endif

  double prodscal_RZ = prod_scal_ijk(R, Z);
  double beta = prodscal_RZ / dold;
  dold = prodscal_RZ;

  op_multiply(P, beta);
  op_sub(P, Z);
}
}

#endif

inline double ajouter_alpha_v_multiple_(IJK_Field_double& x, ArrOfDouble& coeff, VECT(IJK_Field_double) & y, int n, int nfirst)
{
  if (n > 4)
    {
      Cerr << "Erreur ajouter_alpha_v_multiple" << finl;
      Process::exit();
    }
  const int ni = x.ni();
  const int nj = x.nj();
  const int nk = x.nk();
  double * x_ptr = x.data().addr();
  double * y_ptr[4];
  double c[4];
  int nn;
  double somme = 0.;
  for (nn = 0; nn < n; nn++)
    {
      y_ptr[nn] = y[nfirst + nn].data().addr();
      c[nn] = coeff[nfirst + nn];
    }
  for (int k = 0; k < nk; k++)
    {
      for (int j = 0; j < nj; j++)
        {
          int index = x.linear_index(0,j,k);
          for (int i = 0; i < ni; i++)
            {
              double val = x_ptr[index+i];
              for (nn = 0; nn < n; nn++)
                val += c[nn] * y_ptr[nn][index+i];
              x_ptr[index+i] = val;
              somme += val * val;
            }
        }
    }
  return somme;
}

// Calcule ceci
//   x += coeff[0] * y[0] + ... + coeff[n-1] * y[n-1]
// Renvoie la somme des x^2 du resultat sur le processeur local
double ajouter_alpha_v_multiple(IJK_Field_double& x, ArrOfDouble& coeff, VECT(IJK_Field_double) & y, int n)
{
  int i = 0;
  double somme = 0.;
  while (i < n)
    {
      int nn = n - i;
      if (nn > 4)
        nn = 4;
      if (nn == 1)
        somme += ajouter_alpha_v_multiple_(x, coeff, y, 1, i);
      else if (nn == 2)
        somme += ajouter_alpha_v_multiple_(x, coeff, y, 2, i);
      else if (nn == 3)
        somme += ajouter_alpha_v_multiple_(x, coeff, y, 3, i);
      else if (nn == 4)
        somme += ajouter_alpha_v_multiple_(x, coeff, y, 4, i);

      i += nn;
    }
  return somme;
}

inline void calcul_produits_scalaires_(VECT(IJK_Field_double) & x, int n, int nfirst, int m, ArrOfDouble& resu)
{
  if (n > 4)
    {
      Cerr << "Erreur " << finl;
      Process::exit();
    }
  const int ni = x[0].ni();
  const int nj = x[0].nj();
  const int nk = x[0].nk();
  double * x_ptr = x[m].data().addr();
  double * y_ptr[4];
  double c[4] = { 0., 0., 0., 0. };
  int nn;
  for (nn = 0; nn < n; nn++)
    {
      y_ptr[nn] = x[nfirst + nn].data().addr();
      c[nn] = 0;
    }
  for (int k = 0; k < nk; k++)
    {
      for (int j = 0; j < nj; j++)
        {
          int index = x[0].linear_index(0,j,k);
          for (int i = 0; i < ni; i++)
            {
              double val = x_ptr[index+i];
              for (nn = 0; nn < n; nn++)
                c[nn] += val * y_ptr[nn][index+i];
            }
        }
    }
  for (nn = 0; nn < n; nn++)
    resu[nfirst + nn] += c[nn];
}

// Calcule ceci, pour i=0..n avec n = resu.size_array()-1
//   resu[i] = x[i] scalaire x[n]
// Renvoie la somme des x^2 du resultat sur le processeur local
void calcul_produits_scalaires(VECT(IJK_Field_double) & x, ArrOfDouble& resu)
{
  int i = 0;
  resu = 0.;
  const int n = resu.size_array() - 1;
  while (i < n)
    {
      int nn = n - i;
      if (nn > 4)
        nn = 4;
      if (nn == 1)
        calcul_produits_scalaires_(x, 1, i, n, resu);
      else if (nn == 2)
        calcul_produits_scalaires_(x, 2, i, n, resu);
      else if (nn == 3)
        calcul_produits_scalaires_(x, 3, i, n, resu);
      else if (nn == 4)
        calcul_produits_scalaires_(x, 4, i, n, resu);
      i += nn;
    }
  mp_sum_for_each_item(resu);
}

// Gmres preconditionne par multigrille.
// si plus de 3 vecteurs de base, semble atteindre la limite de precision numerique...
void Multigrille_base::resoudre_avec_gmres(IJK_Field_double& x, IJK_Field_double& b, IJK_Field_double& residu)
{
  int n_krilov = n_krilov_;
  DoubleTab hessenberg(n_krilov + 1, n_krilov);

  // Espace de Krilov
  VECT(IJK_Field_double) krilov_space;
  // Vecteurs des M^(-1) * krilov_space[i] ou M^-1 est le preconditionneur:
  VECT(IJK_Field_double) m_krilov_space;

  {
    IJK_Field_double titi;
    for (int ii=0; ii < n_krilov+1; ii++)
      krilov_space.add(titi);
    for (int ii=0; ii < n_krilov; ii++)
      m_krilov_space.add(titi);
  }
  krilov_space[0] = b;
  for (int ii=0; ii < n_krilov; ii++)
    {
      //int sz = b.data().size_array();
#if 0
      krilov_space[ii+1].data().resize_array(sz, Array_base::NOCOPY_NOINIT);
      m_krilov_space[ii].data().resize_array(sz, Array_base::NOCOPY_NOINIT);
#endif
      alloc_field(krilov_space[ii+1], 0);
      alloc_field(m_krilov_space[ii], 0, true /* with additional layers for jacobi sweeps */);
    }

  x.data() = 0.;

  for (int iter = 0; ; iter++)
    {

      // Hypothese de depart: krilov_space[0] = -residu
      const double norme_b = norme_ijk(krilov_space[0]);

      if (impr_gmres_)
        Cout << "gmres iteration " << iter << " norme(residu) " << norme_b << finl;
      if (norme_b < seuil_ || norme_b == 0.)
        {
          if (impr_gmres_)
            Cout << "gmres: norme(residu) < seuil=" << seuil_ << " => return" << finl;
          return;
        }
      if (iter >= max_iter_gmres_)
        {
          Cerr << "Error in Multigrille_base::resoudre_avec_gmres: did not converge in " << max_iter_gmres_ << " restarts."
               << "\n Residue= " << norme_b << finl;
          Process::exit();
        }
      krilov_space[0].data() *= (1. / norme_b);

      hessenberg = 0.;

      for (int i = 0; i < n_krilov; i++)
        {
          // Produit matrice vecteur : v1 = A * M^(-1) * v0  (ou M^(-1) est une approx de A^(-1) par multigrille)
          m_krilov_space[i].data() = 0.;
          m_krilov_space[i].shift_k_origin(needed_kshift_for_jacobi(0) - m_krilov_space[i].k_shift());
          krilov_space[i].echange_espace_virtuel(krilov_space[i].ghost());
          // Stockage de M^-1 * v0 dans m_krilov_space[i]
          // et on met le residu dans krilov_space[i+1]
          multigrille(m_krilov_space[i], krilov_space[i], krilov_space[i+1]);

          // remarque Titi23
          // On obtient krilov_space[i+1] = A * m_krilov_space[i] - krilov_space[i]
          // normalement, on devrait faire
          //  krilov_space[i+1] += krilov_space[i]
          // L'orthogonalisation va retirer la composante krilov_space[i],
          // mais va calculer "prod_scal_ijk(krilov_space[i+1], krilov_space[i]) - 1"

          // Orthogonalisation:
          //  v0 = somme pour 0 <= j <= i des (krilov_space[j] * hessenberg(j, i)
          ArrOfDouble produit_scal(i+2);
          ArrOfDouble coeff(i+1);
          calcul_produits_scalaires(krilov_space, produit_scal);
          for (int j = 0; j <= i; j++)
            {
              double h = produit_scal[j];
              coeff[j] = -h;
              //norme2_prevue -= h*h;
              if (j == i)
                {
                  // voir Titi23 ci-dessus:
                  // on n'a pas rajoute krilov_space[i] toute a l'heure a krilov_space[i+1],
                  // le produit scalaire a stocker dans hessenberg vaut donc 1 de plus:
                  h += 1.;
                }
              hessenberg(j, i) = h;
            }
          double norme_v0 = ajouter_alpha_v_multiple(krilov_space[i+1], coeff, krilov_space, i+1);
          norme_v0 = sqrt(mp_sum(norme_v0));
          hessenberg(i + 1, i) = norme_v0;
          krilov_space[i+1].data() *= 1. / norme_v0;
        }

      DoubleTab mat(n_krilov + 1, n_krilov);
      ArrOfDouble r__(n_krilov + 1);
      triangularise(hessenberg, norme_b, mat, r__);

      //...Solution of linear system
      for (int i = n_krilov - 1; i >= 0; i--)
        {
          r__[i] /= mat(i, i);
          for (int j = i-1; j >= 0; j--)
            r__[j] -= mat(j, i) * r__[i];
        }
      ajouter_alpha_v_multiple(x, r__, m_krilov_space, n_krilov);
      if (impr_gmres_)
        {
          Cout << "facteurs r : ";
          for (int i = 0; i < r__.size_array(); i++)
            Cout << r__[i] << " ";
          Cout << finl;
          if (impr_gmres_ > 1)
            {
              Cout << "matrice de hessenberg " << hessenberg << finl;
            }
        }
      // On stocke le residu dans krilov_space[0] pour l'iteration suivante:
      jacobi_residu(x, &b, 0 /* grid_level */, 0 /* no jacobi */, &krilov_space[0]);
      prepare_secmem(krilov_space[0]);
      op_negate(krilov_space[0]);
    }
}

int Multigrille_base::resoudre_systeme(const Matrice_Base& a, const DoubleVect& b, DoubleVect& x)
{
  if (solver_precision_ == precision_double_)
    resoudre_systeme_double(a, b, x);
  else if (solver_precision_ == precision_float_)
    resoudre_systeme_float(a, b, x);
  else
    resoudre_systeme_double(a, b, x);
  return 1;
}

void Multigrille_base::resoudre_systeme_IJK(const IJK_Field_float& rhs, IJK_Field_float& x)
{
  if (solver_precision_ == precision_float_)
    {
      resoudre_systeme_IJK_float(rhs, x);
    }
  else
    {
      resoudre_systeme_IJK_double(rhs, x);
    }
}

void Multigrille_base::resoudre_systeme_IJK_float(const IJK_Field_float& rhs, IJK_Field_float& x)
{
  IJK_Field_float& ijk_b = get_storage_float(STORAGE_RHS, 0);
  IJK_Field_float& ijk_x = get_storage_float(STORAGE_X, 0);
  ijk_x.shift_k_origin(needed_kshift_for_jacobi(0) - ijk_x.k_shift());
  int i, j, k;
  const int imax = x.ni();
  const int jmax = x.nj();
  const int kmax = x.nk();
  for (k = 0; k < kmax; k++)
    for (j = 0; j < jmax; j++)
      for (i = 0; i < imax; i++)
        {
          ijk_b(i,j,k) = rhs(i,j,k);
        }

  solve_ijk_in_storage_float();

  for (k = 0; k < kmax; k++)
    for (j = 0; j < jmax; j++)
      for (i = 0; i < imax; i++)
        {
          x(i,j,k) = ijk_x(i,j,k);
        }
}
void Multigrille_base::resoudre_systeme_IJK_float(const IJK_Field_double& rhs, IJK_Field_double& x)
{
  IJK_Field_float& ijk_b = get_storage_float(STORAGE_RHS, 0);
  IJK_Field_float& ijk_x = get_storage_float(STORAGE_X, 0);
  ijk_x.shift_k_origin(needed_kshift_for_jacobi(0) - ijk_x.k_shift());
  int i, j, k;
  const int imax = x.ni();
  const int jmax = x.nj();
  const int kmax = x.nk();
  for (k = 0; k < kmax; k++)
    for (j = 0; j < jmax; j++)
      for (i = 0; i < imax; i++)
        {
          ijk_b(i,j,k) = rhs(i,j,k);
        }

  solve_ijk_in_storage_float();

  for (k = 0; k < kmax; k++)
    for (j = 0; j < jmax; j++)
      for (i = 0; i < imax; i++)
        {
          x(i,j,k) = ijk_x(i,j,k);
        }
}

void Multigrille_base::solve_ijk_in_storage_float()
{
  IJK_Field_float& ijk_b = get_storage_float(STORAGE_RHS, 0);
  IJK_Field_float& ijk_x = get_storage_float(STORAGE_X, 0);
  IJK_Field_float& ijk_residu = get_storage_float(STORAGE_RESIDUE, 0);

  prepare_secmem(ijk_b);
  ijk_b.echange_espace_virtuel(ijk_b.ghost());

  double norm_residue;
  norm_residue = multigrille(ijk_x, ijk_b, ijk_residu);
  if (norm_residue > seuil_)
    {
      Cerr << "Error in Multigrille_base: single precision pure multigrid solver did not converge to requested precision ("
           << seuil_ << ")\n Residue at end of solver= " << norm_residue << finl;
      Process::exit();
    }
}

void Multigrille_base::resoudre_systeme_float(const Matrice_Base& a, const DoubleVect& b, DoubleVect& x)
{
  IJK_Field_float& ijk_b = get_storage_float(STORAGE_RHS, 0);
  IJK_Field_float& ijk_x = get_storage_float(STORAGE_X, 0);
  ijk_x.shift_k_origin(needed_kshift_for_jacobi(0) - ijk_x.k_shift());

  convert_to_ijk(b, ijk_b);

  solve_ijk_in_storage_float();

  convert_from_ijk(ijk_x, x);

  x.echange_espace_virtuel();

  if (check_residu_)
    {
#if 0
      int i, j, k;
      for (i = 0; i < ijk_x.ni(); i++)
        for (j = 0; j < ijk_x.nj(); j++)
          for (k = 0; k < ijk_x.nk(); k++)
            ijk_b(i,j,k) = 0.*(double) rand() / (double) RAND_MAX+0.;
      ijk_b.echange_espace_virtuel(1);
      DoubleVect bb(b);
      bb = 0.;
      convert_from_ijk(ijk_b, bb);

      const Matrice_Morse_Sym a_morse = ref_cast(Matrice_Morse_Sym, ref_cast(Matrice_Bloc, a)(0,0).valeur());
      Cerr << "Matrice A : tab1 " << a_morse.tab1_
           << finl << "tab2 " << a_morse.tab2_
           << finl << "coeff " << a_morse.coeff_ << finl;

      for (i = 0; i < ijk_x.ni(); i++)
        for (j = 0; j < ijk_x.nj(); j++)
          for (k = 0; k < ijk_x.nk(); k++)
            {
              ijk_x.data() = 0.;
              ijk_x(i,j,k) = 1.;
              convert_from_ijk(ijk_x, x);
              double nx = mp_norme_vect(x);
              ijk_residu.data() = 0.;
              jacobi_residu(ijk_x, &ijk_b, 0, 0, &ijk_residu);
              DoubleVect residu(bb);
              a.multvect(x, residu);
              residu -= bb;
              double r1 = mp_norme_vect(residu);
              double r2 = norme_ijk(ijk_residu);
              if (fabs(r2-r1)>1e-10)
                Cerr << "ijk " << i << " " << j << " " << k << " " << r1 << " " << r2 << "     " << r2 - r1 <<  " nx=" << nx << finl;
            }


      Process::exit();
#endif

      // Calcul du residu
      DoubleVect residu(b);
      a.multvect(x, residu);

      const Matrice_Bloc& matrice_bloc=ref_cast(Matrice_Bloc,a);
      const Matrice_Morse_Sym& la_matrice =ref_cast(Matrice_Morse_Sym,matrice_bloc.get_bloc(0,0).valeur());
      // Terme diagonal multiplie par 2 dans Assembleur_P_VDF.cpp: assembler_QC()
      if (Process::je_suis_maitre())
        residu[0] -= x[0] * la_matrice(0,0) * 0.5;
      Cout << "Norme de Ax et residu: " << mp_norme_vect(residu);
      residu -= b;
      Cout << " " << mp_norme_vect(residu) << finl;
    }

}
void Multigrille_base::resoudre_systeme_IJK(const IJK_Field_double& rhs, IJK_Field_double& x)
{
  if (solver_precision_ == precision_float_)
    {
      resoudre_systeme_IJK_float(rhs, x);
    }
  else
    {
      resoudre_systeme_IJK_double(rhs, x);
    }
}

void Multigrille_base::resoudre_systeme_IJK_double(const IJK_Field_float& rhs, IJK_Field_float& x)
{
  IJK_Field_double& ijk_b = get_storage_double(STORAGE_RHS, 0);
  IJK_Field_double& ijk_x = get_storage_double(STORAGE_X, 0);
  ijk_x.shift_k_origin(needed_kshift_for_jacobi(0) - ijk_x.k_shift());
  int i, j, k;
  const int imax = x.ni();
  const int jmax = x.nj();
  const int kmax = x.nk();
  for (k = 0; k < kmax; k++)
    for (j = 0; j < jmax; j++)
      for (i = 0; i < imax; i++)
        {
          ijk_b(i,j,k) = rhs(i,j,k);
        }

  solve_ijk_in_storage_double();

  for (k = 0; k < kmax; k++)
    for (j = 0; j < jmax; j++)
      for (i = 0; i < imax; i++)
        {
          x(i,j,k) = ijk_x(i,j,k);
        }
}
void Multigrille_base::resoudre_systeme_IJK_double(const IJK_Field_double& rhs, IJK_Field_double& x)
{
  IJK_Field_double& ijk_b = get_storage_double(STORAGE_RHS, 0);
  IJK_Field_double& ijk_x = get_storage_double(STORAGE_X, 0);
  ijk_x.shift_k_origin(needed_kshift_for_jacobi(0) - ijk_x.k_shift());
  int i, j, k;
  const int imax = x.ni();
  const int jmax = x.nj();
  const int kmax = x.nk();
  for (k = 0; k < kmax; k++)
    for (j = 0; j < jmax; j++)
      for (i = 0; i < imax; i++)
        {
          ijk_b(i,j,k) = rhs(i,j,k);
        }

  solve_ijk_in_storage_double();

  for (k = 0; k < kmax; k++)
    for (j = 0; j < jmax; j++)
      for (i = 0; i < imax; i++)
        {
          x(i,j,k) = ijk_x(i,j,k);
        }
}

void Multigrille_base::solve_ijk_in_storage_double()
{
  IJK_Field_double& ijk_b = get_storage_double(STORAGE_RHS, 0);
  IJK_Field_double& ijk_x = get_storage_double(STORAGE_X, 0);
  IJK_Field_double& ijk_residu = get_storage_double(STORAGE_RESIDUE, 0);

  prepare_secmem(ijk_b);
  ijk_b.echange_espace_virtuel(ijk_b.ghost());

  if (solver_precision_ == precision_double_)
    {
      if (max_iter_gcp_ > 0)
        {
          resoudre_avec_gcp(ijk_x, ijk_b, ijk_residu);
        }
      else if (max_iter_gmres_ > 0)
        {
          resoudre_avec_gmres(ijk_x, ijk_b, ijk_residu);
        }
      else if (solv_jacobi_ > 0)
        {
          static int fcount = 0;
          ijk_x.data() = 0.;
          for (int i = 0; i < solv_jacobi_; i++)
            {
              jacobi_residu(ijk_x, &ijk_b, 0, 2 /* jacobi iterations */, &ijk_residu);
              dump_lata("x", ijk_x, fcount);
              dump_lata("residu", ijk_residu, fcount);
              fcount++;
            }
        }
      else
        {
          double norm_residue;
          norm_residue = multigrille(ijk_x, ijk_b, ijk_residu);
          if (norm_residue > seuil_)
            {
              Cerr << "Error in Multigrille_base: double precision pure multigrid solver did not converge to requested precision ("
                   << seuil_ << ")\n Residue at end of solver= " << norm_residue << finl;
              Process::exit();
            }
        }
    }
  else
    {
      // mixed precision solver
      ijk_x.data() = 0.;
      IJK_Field_float& float_b = get_storage_float(STORAGE_RHS, 0);
      IJK_Field_float& float_x = get_storage_float(STORAGE_X, 0);
      IJK_Field_float& float_residue = get_storage_float(STORAGE_RESIDUE, 0);
      float_b.data() = 0.;

      int i, j, k;
      const int ni = ijk_x.ni();
      const int nj = ijk_x.nj();
      const int nk = ijk_x.nk();
      for (k = 0; k < nk; k++)
        for (j = 0; j < nj; j++)
          for (i = 0; i < ni; i++)
            float_b(i,j,k) = ijk_b(i,j,k);
      int iteration = 0;
      do
        {
          if (iteration > 0)
            for (k = 0; k < nk; k++)
              for (j = 0; j < nj; j++)
                for (i = 0; i < ni; i++)
                  float_b(i,j,k) = -ijk_residu(i,j,k);


          // Launch multigrid solver in single precision:
          float_x.data() = 0.;
          prepare_secmem(float_b);
          float_b.echange_espace_virtuel(float_b.ghost());
          float_x.shift_k_origin(needed_kshift_for_jacobi(0) - float_x.k_shift());
          double single_precision_residue = multigrille(float_x, float_b, float_residue);

          // Update x:
          for (k = 0; k < nk; k++)
            for (j = 0; j < nj; j++)
              for (i = 0; i < ni; i++)
                ijk_x(i,j,k) += float_x(i,j,k);

          if (single_precision_residue < seuil_)
            break;

          // Compute residue in double precision:
          jacobi_residu(ijk_x, &ijk_b, 0, 0 /* jacobi iterations */, &ijk_residu);
          double nr = norme_ijk(ijk_residu);
          if (impr_)
            Cout << "Mixed precision solver iteration " << iteration
                 << " singleprecision residue= " << single_precision_residue
                 << " doubleprecision residue= " << nr << finl;

          iteration++;
          if (iteration > max_iter_mixed_solver_)
            {
              Cerr << "Error in Multigrille_base: mixed precision solver did not converge in "
                   << max_iter_mixed_solver_ << " iterations." << finl;
              Process::exit();
            }
        }
      while (1);
    }
}

void Multigrille_base::resoudre_systeme_double(const Matrice_Base& a, const DoubleVect& b, DoubleVect& x)
{
  IJK_Field_double& ijk_b = get_storage_double(STORAGE_RHS, 0);
  IJK_Field_double& ijk_x = get_storage_double(STORAGE_X, 0);
  ijk_x.shift_k_origin(needed_kshift_for_jacobi(0) - ijk_x.k_shift());

  convert_to_ijk(b, ijk_b);

  solve_ijk_in_storage_double();

  convert_from_ijk(ijk_x, x);

  x.echange_espace_virtuel();

  if (check_residu_)
    {
#if 0
      int i, j, k;
      for (i = 0; i < ijk_x.ni(); i++)
        for (j = 0; j < ijk_x.nj(); j++)
          for (k = 0; k < ijk_x.nk(); k++)
            ijk_b(i,j,k) = 0.*(double) rand() / (double) RAND_MAX+0.;
      ijk_b.echange_espace_virtuel(1);
      DoubleVect bb(b);
      bb = 0.;
      convert_from_ijk(ijk_b, bb);

      const Matrice_Morse_Sym a_morse = ref_cast(Matrice_Morse_Sym, ref_cast(Matrice_Bloc, a)(0,0).valeur());
      Cerr << "Matrice A : tab1 " << a_morse.tab1_
           << finl << "tab2 " << a_morse.tab2_
           << finl << "coeff " << a_morse.coeff_ << finl;

      for (i = 0; i < ijk_x.ni(); i++)
        for (j = 0; j < ijk_x.nj(); j++)
          for (k = 0; k < ijk_x.nk(); k++)
            {
              ijk_x.data() = 0.;
              ijk_x(i,j,k) = 1.;
              convert_from_ijk(ijk_x, x);
              double nx = mp_norme_vect(x);
              ijk_residu.data() = 0.;
              jacobi_residu(ijk_x, &ijk_b, 0, 0, &ijk_residu);
              DoubleVect residu(bb);
              a.multvect(x, residu);
              residu -= bb;
              double r1 = mp_norme_vect(residu);
              double r2 = norme_ijk(ijk_residu);
              if (fabs(r2-r1)>1e-10)
                Cerr << "ijk " << i << " " << j << " " << k << " " << r1 << " " << r2 << "     " << r2 - r1 <<  " nx=" << nx << finl;
            }


      Process::exit();
#endif

      // Calcul du residu
      DoubleVect residu(b);
      a.multvect(x, residu);

      const Matrice_Bloc& matrice_bloc=ref_cast(Matrice_Bloc,a);
      const Matrice_Morse_Sym& la_matrice =ref_cast(Matrice_Morse_Sym,matrice_bloc.get_bloc(0,0).valeur());
      // Terme diagonal multiplie par 2 dans Assembleur_P_VDF.cpp: assembler_QC()
      if (Process::je_suis_maitre())
        residu[0] -= x[0] * la_matrice(0,0) * 0.5;
      Cout << "Norme de Ax et residu: " << mp_norme_vect(residu);
      residu -= b;
      Cout << " " << mp_norme_vect(residu) << finl;
    }

}
int Multigrille_base::resoudre_systeme(const Matrice_Base& a, const DoubleVect& b, DoubleVect& x, int n)
{
  resoudre_systeme(a, b, x);
  return 1;
}

// This solver does not need rhs to have updated virtual space
int Multigrille_base::get_flag_updated_input() const
{
  return 0;
}

int Multigrille_base::nsweeps_jacobi_residu(int level) const
{
  int i1 = level;
  int i2 = level;
  if (level > pre_smooth_steps_.size_array() - 1)
    i1 = pre_smooth_steps_.size_array() - 1;
  if (level > smooth_steps_.size_array() - 1)
    i2 = smooth_steps_.size_array() - 1;
  int nsweeps = max(pre_smooth_steps_[i1], smooth_steps_[i2]) + 1;
  return nsweeps;
}
